Day019
================

HW (Kaggle)鐵達尼生存預測精簡版
-------------------------------

<https://www.kaggle.com/c/titanic>

Packages loading

``` r
library(purrr)
library(plyr)
library(tidyverse)
library(caret)
library(ROCR)
```

Data loading

``` r
df_train <- read.csv("data/titanic_train.csv")
df_test <- read.csv("data/titanic_test.csv")
sapply(list(df_train=df_train, df_test=df_test), dim) %>% 'rownames<-'(c('nrow','ncol')) 
```

    ##      df_train df_test
    ## nrow      891     418
    ## ncol       12      11

Setting training and testing data

``` r
train_y <- df_train$Survived
ids <- df_test$PassengerId
df_train <- df_train %>% select(-c("Survived","PassengerId"))
df_test <- df_test %>% select(-"PassengerId")
df <- rbind(df_train, df_test)
head(df)
```

    ##   Pclass                                                Name    Sex Age
    ## 1      3                             Braund, Mr. Owen Harris   male  22
    ## 2      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38
    ## 3      3                              Heikkinen, Miss. Laina female  26
    ## 4      1        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35
    ## 5      3                            Allen, Mr. William Henry   male  35
    ## 6      3                                    Moran, Mr. James   male  NA
    ##   SibSp Parch           Ticket    Fare Cabin Embarked
    ## 1     1     0        A/5 21171  7.2500              S
    ## 2     1     0         PC 17599 71.2833   C85        C
    ## 3     0     0 STON/O2. 3101282  7.9250              S
    ## 4     1     0           113803 53.1000  C123        S
    ## 5     0     0           373450  8.0500              S
    ## 6     0     0           330877  8.4583              Q

秀出資料欄位的類型與數量

``` r
table(sapply(df, class))
```

    ## 
    ##  factor integer numeric 
    ##       5       3       2

確定只有 integer, numeric, factor 三種類型後, 分別將欄位名稱存於三個 vector 中

``` r
feature_type <- sapply(df, class)
int_var <- feature_type[which(feature_type == "integer")] %>% as.data.frame %>% rownames
num_var <- feature_type[which(feature_type == "numeric")] %>% as.data.frame %>% rownames
fac_var <- feature_type[which(feature_type == "factor")] %>% as.data.frame %>% rownames
list(integer_feature = int_var,
     numeric_feature = num_var,
     factor_feature = fac_var)
```

    ## $integer_feature
    ## [1] "Pclass" "SibSp"  "Parch" 
    ## 
    ## $numeric_feature
    ## [1] "Age"  "Fare"
    ## 
    ## $factor_feature
    ## [1] "Name"     "Sex"      "Ticket"   "Cabin"    "Embarked"

削減文字型欄位, 只剩數值型欄位

``` r
df <- df %>% select(-fac_var)
train_num <- length(train_y)
head(df)
```

    ##   Pclass Age SibSp Parch    Fare
    ## 1      3  22     1     0  7.2500
    ## 2      1  38     1     0 71.2833
    ## 3      3  26     0     0  7.9250
    ## 4      1  35     1     0 53.1000
    ## 5      3  35     0     0  8.0500
    ## 6      3  NA     0     0  8.4583

作業1
-----

試著在補空值區塊, 替換並執行兩種以上填補的缺值, 看看何者比較好?

空值補 -1, 做羅吉斯迴歸

``` r
df_m1 <- df %>% replace(., is.na(.), -1)
train_x <- df_m1[1:train_num,]
train_y <- as.factor(train_y)
levels(train_y) <- make.names(levels(factor(train_y)))

train <- train_x %>% mutate(Survived = train_y)
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 713, 713, 712, 713, 713 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7209225  0.8579983  0.4595482

空值補 0, 做羅吉斯迴歸

``` r
df_0 <- df %>% replace(., is.na(.), 0)
train_x <- df_0[1:train_num,]
train_y <- as.factor(train_y)
levels(train_y) <- make.names(levels(factor(train_y)))

train <- train_x %>% mutate(Survived = train_y)
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 712, 714, 712, 713, 713 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7214879  0.8579316  0.4531543

空值補平均值, 做羅吉斯迴歸

``` r
na2mean <- function(x) {replace(x, is.na(x), mean(x, na.rm = TRUE))}
df_mean <- df %>% replace(TRUE, lapply(df, na2mean))
train_x <- df_mean[1:train_num,] 
train_y <- as.factor(train_y)
levels(train_y) <- make.names(levels(factor(train_y)))

train <- train_x %>% mutate(Survived = train_y)
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 712, 713, 714, 712, 713 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7262261  0.8543453  0.4530691

作業2
-----

使用不同的標準化方式 ( 原值 / 最小最大化 / 標準化 )，搭配羅吉斯迴歸模型，何者效果最好?

空值補平均值, 做羅吉斯迴歸

``` r
na2mean <- function(x) {replace(x, is.na(x), mean(x, na.rm = TRUE))}
df_mean <- df %>% replace(TRUE, lapply(df, na2mean))
train_x <- df_mean[1:train_num,] 
train_y <- as.factor(train_y)
levels(train_y) <- make.names(levels(factor(train_y)))

train <- train_x %>% mutate(Survived = train_y)
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 713, 712, 714, 713, 712 
    ## Resampling results:
    ## 
    ##   ROC       Sens       Spec     
    ##   0.729311  0.8652544  0.4502131

空值補平均值, 最小最大化, 做羅吉斯迴歸

``` r
na2mean <- function(x) {replace(x, is.na(x), mean(x, na.rm = TRUE))}
df_mean <- df %>% replace(TRUE, lapply(df, na2mean))
train_x <- df_mean[1:train_num,] 
normal <- preProcess(train_x, method = "range", rangeBounds = c(0,1))
train_normal <- predict(normal, train_x)
head(train_normal)
```

    ##   Pclass       Age SibSp Parch       Fare
    ## 1      1 0.2711737 0.125     0 0.01415106
    ## 2      0 0.4722292 0.125     0 0.13913574
    ## 3      1 0.3214375 0.000     0 0.01546857
    ## 4      0 0.4345313 0.125     0 0.10364430
    ## 5      1 0.4345313 0.000     0 0.01571255
    ## 6      1 0.3702078 0.000     0 0.01650950

``` r
train_y <- as.factor(train_y)
levels(train_y) <- make.names(levels(factor(train_y)))

train <- train_normal %>% mutate(Survived = train_y)
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 714, 713, 712, 713, 712 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec    
    ##   0.7290411  0.8687406  0.441347

空值補平均值, 標準化, 做羅吉斯迴歸

``` r
na2mean <- function(x) {replace(x, is.na(x), mean(x, na.rm = TRUE))}
df_mean <- df %>% replace(TRUE, lapply(df, na2mean))
train_x <- df_mean[1:train_num,] 
standard <- preProcess(train_x, method = c("center", "scale"), rangeBounds = c(0,1))
train_standard <- predict(standard, train_x)
head(train_standard)
```

    ##       Pclass         Age      SibSp      Parch       Fare
    ## 1  0.8269128 -0.59491975  0.4325504 -0.4734077 -0.5021631
    ## 2 -1.5652278  0.63563950  0.4325504 -0.4734077  0.7864036
    ## 3  0.8269128 -0.28727994 -0.4742788 -0.4734077 -0.4885799
    ## 4 -1.5652278  0.40490964  0.4325504 -0.4734077  0.4204941
    ## 5  0.8269128  0.40490964 -0.4742788 -0.4734077 -0.4860644
    ## 6  0.8269128  0.01121818 -0.4742788 -0.4734077 -0.4778481

``` r
train_y <- as.factor(train_y)
levels(train_y) <- make.names(levels(factor(train_y)))

train <- train_standard %>% mutate(Survived = train_y)
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 714, 712, 713, 713, 712 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7318067  0.8598165  0.4386189
