Day025
================

HW (Kaggle)計程車費率預測
-------------------------

<https://www.kaggle.com/c/new-york-city-taxi-fare-prediction>

Packages loading

``` r
library(lubridate)
library(magrittr)
library(tidyverse)
library(caret)
library(hash)
library(pROC)
```

Data loading

``` r
df <- read.csv("data/taxi_data1.csv")
train_Y <- df %>% select("fare_amount")
df <- df %>% select(-"fare_amount")
sapply(list(df=df), dim) %>% 'rownames<-'(c('nrow','ncol')) 
```

    ##        df
    ## nrow 5000
    ## ncol    6

``` r
df %>% head
```

    ##           pickup_datetime pickup_longitude pickup_latitude
    ## 1 2011-10-21 23:54:10 UTC        -73.99058        40.76107
    ## 2 2015-02-03 10:42:03 UTC        -73.98840        40.72343
    ## 3 2014-03-16 18:58:58 UTC        -74.01578        40.71511
    ## 4 2009-06-13 16:10:54 UTC        -73.97732        40.78728
    ## 5 2014-06-12 03:25:56 UTC        -73.98968        40.72972
    ## 6 2011-07-16 01:19:59 UTC        -73.99763        40.72181
    ##   dropoff_longitude dropoff_latitude passenger_count
    ## 1         -73.98113         40.75863               2
    ## 2         -73.98965         40.74170               1
    ## 3         -74.01203         40.70789               2
    ## 4         -73.95803         40.77884               3
    ## 5         -73.98249         40.76189               3
    ## 6         -74.00976         40.70994               1

時間特徵分解方式:使用package: lubridate

``` r
df$pickup_datetime <- as.POSIXct(df$pickup_datetime, format='%Y-%m-%d %H:%M:%S UTC')
df$pickup_year <- year(df$pickup_datetime) 
df$pickup_month <- month(df$pickup_datetime) 
df$pickup_day <- day(df$pickup_datetime) 
df$pickup_hour <- hour(df$pickup_datetime) 
df$pickup_minute <- minute(df$pickup_datetime) 
df$pickup_second <- second(df$pickup_datetime) 
df %>% head
```

    ##       pickup_datetime pickup_longitude pickup_latitude dropoff_longitude
    ## 1 2011-10-21 23:54:10        -73.99058        40.76107         -73.98113
    ## 2 2015-02-03 10:42:03        -73.98840        40.72343         -73.98965
    ## 3 2014-03-16 18:58:58        -74.01578        40.71511         -74.01203
    ## 4 2009-06-13 16:10:54        -73.97732        40.78728         -73.95803
    ## 5 2014-06-12 03:25:56        -73.98968        40.72972         -73.98249
    ## 6 2011-07-16 01:19:59        -73.99763        40.72181         -74.00976
    ##   dropoff_latitude passenger_count pickup_year pickup_month pickup_day
    ## 1         40.75863               2        2011           10         21
    ## 2         40.74170               1        2015            2          3
    ## 3         40.70789               2        2014            3         16
    ## 4         40.77884               3        2009            6         13
    ## 5         40.76189               3        2014            6         12
    ## 6         40.70994               1        2011            7         16
    ##   pickup_hour pickup_minute pickup_second
    ## 1          23            54            10
    ## 2          10            42             3
    ## 3          18            58            58
    ## 4          16            10            54
    ## 5           3            25            56
    ## 6           1            19            59

``` r
df_temp <- df %>% select(-"pickup_datetime")

# 最小最大化
normal <- preProcess(df_temp, method = "range", rangeBounds = c(0,1))
train_X <- predict(normal, df_temp)
```

線性迴歸

``` r
train <- data.frame(train_X, fare_amount = train_Y)

control <- trainControl(method="cv", number=5, repeats = 5)
model.lr <- train(fare_amount~., data = train, method = 'glm', trControl=control)
model.lr
```

    ## Generalized Linear Model 
    ## 
    ## 5000 samples
    ##   11 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 4000, 4000, 4000, 4001, 3999 
    ## Resampling results:
    ## 
    ##   RMSE      Rsquared  MAE     
    ##   9.593019  0.033506  5.984752

梯度提升樹

``` r
control <- trainControl(method="cv", number=5, repeats = 5)
model.gbm <- train(fare_amount~., data = train, method = "gbm", trControl = control, verbose = FALSE)
model.gbm
```

    ## Stochastic Gradient Boosting 
    ## 
    ## 5000 samples
    ##   11 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 4000, 4001, 4000, 3999, 4000 
    ## Resampling results across tuning parameters:
    ## 
    ##   interaction.depth  n.trees  RMSE      Rsquared   MAE     
    ##   1                   50      7.851388  0.4021546  5.068674
    ##   1                  100      7.342257  0.4558327  4.733302
    ##   1                  150      7.149945  0.4735695  4.586357
    ##   2                   50      6.345227  0.6116544  4.203194
    ##   2                  100      5.846374  0.6489423  3.819883
    ##   2                  150      5.700509  0.6626720  3.647857
    ##   3                   50      5.792578  0.6614922  3.808490
    ##   3                  100      5.535640  0.6811468  3.518364
    ##   3                  150      5.372656  0.6980880  3.350315
    ## 
    ## Tuning parameter 'shrinkage' was held constant at a value of 0.1
    ## 
    ## Tuning parameter 'n.minobsinnode' was held constant at a value of 10
    ## RMSE was used to select the optimal model using the smallest value.
    ## The final values used for the model were n.trees = 150,
    ##  interaction.depth = 3, shrinkage = 0.1 and n.minobsinnode = 10.

作業1
-----

對照範例，試著加入星期幾 (day of week) 與第幾周 (week of year) 這兩項特徵，
看看結果會比原本只有時間特徵分解的結果更好或更差?

``` r
df$pickup_weekday <- wday(df$pickup_datetime) # Sunday = 1
df$pickup_week <- week(df$pickup_datetime) 
df %>% head
```

    ##       pickup_datetime pickup_longitude pickup_latitude dropoff_longitude
    ## 1 2011-10-21 23:54:10        -73.99058        40.76107         -73.98113
    ## 2 2015-02-03 10:42:03        -73.98840        40.72343         -73.98965
    ## 3 2014-03-16 18:58:58        -74.01578        40.71511         -74.01203
    ## 4 2009-06-13 16:10:54        -73.97732        40.78728         -73.95803
    ## 5 2014-06-12 03:25:56        -73.98968        40.72972         -73.98249
    ## 6 2011-07-16 01:19:59        -73.99763        40.72181         -74.00976
    ##   dropoff_latitude passenger_count pickup_year pickup_month pickup_day
    ## 1         40.75863               2        2011           10         21
    ## 2         40.74170               1        2015            2          3
    ## 3         40.70789               2        2014            3         16
    ## 4         40.77884               3        2009            6         13
    ## 5         40.76189               3        2014            6         12
    ## 6         40.70994               1        2011            7         16
    ##   pickup_hour pickup_minute pickup_second pickup_weekday pickup_week
    ## 1          23            54            10              6          42
    ## 2          10            42             3              3           5
    ## 3          18            58            58              1          11
    ## 4          16            10            54              7          24
    ## 5           3            25            56              5          24
    ## 6           1            19            59              7          29

``` r
df_temp <- df %>% select(-"pickup_datetime")

# 最小最大化
normal <- preProcess(df_temp, method = "range", rangeBounds = c(0,1))
train_X <- predict(normal, df_temp)
```

線性迴歸

``` r
train <- data.frame(train_X, fare_amount = train_Y)

control <- trainControl(method="cv", number=5, repeats = 5)
model.lr <- train(fare_amount~., data = train, method = 'glm', trControl=control)
model.lr
```

    ## Generalized Linear Model 
    ## 
    ## 5000 samples
    ##   13 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 4000, 4000, 4000, 4001, 3999 
    ## Resampling results:
    ## 
    ##   RMSE      Rsquared    MAE     
    ##   9.617276  0.03187437  6.003993

梯度提升樹

``` r
control <- trainControl(method="cv", number=5, repeats = 5)
model.gbm <- train(fare_amount~., data = train, method = "gbm", trControl = control, verbose = FALSE)
model.gbm
```

    ## Stochastic Gradient Boosting 
    ## 
    ## 5000 samples
    ##   13 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 4000, 4000, 4000, 4001, 3999 
    ## Resampling results across tuning parameters:
    ## 
    ##   interaction.depth  n.trees  RMSE      Rsquared   MAE     
    ##   1                   50      7.886364  0.3971115  5.108153
    ##   1                  100      7.387847  0.4494693  4.744160
    ##   1                  150      7.236654  0.4626170  4.608227
    ##   2                   50      6.402894  0.6045158  4.222636
    ##   2                  100      5.911165  0.6419071  3.837580
    ##   2                  150      5.727302  0.6601002  3.680639
    ##   3                   50      5.824553  0.6571540  3.833005
    ##   3                  100      5.543066  0.6799674  3.530949
    ##   3                  150      5.411782  0.6930037  3.378021
    ## 
    ## Tuning parameter 'shrinkage' was held constant at a value of 0.1
    ## 
    ## Tuning parameter 'n.minobsinnode' was held constant at a value of 10
    ## RMSE was used to select the optimal model using the smallest value.
    ## The final values used for the model were n.trees = 150,
    ##  interaction.depth = 3, shrinkage = 0.1 and n.minobsinnode = 10.

作業2
-----

對照範例的日週期效果，試著參考投影片完成年週期與周週期的特徵 (也可以用你自己想到的方式)，
看看結果會比範例中的結果更好或更差?

加上"年週期"特徵

``` r
df$year_cycle <- cospi(df$pickup_month/6 + df$pickup_day/180)
df$week_cycle <- sinpi(df$pickup_weekday/3.5 + df$pickup_hour/84)
df %>% head
```

    ##       pickup_datetime pickup_longitude pickup_latitude dropoff_longitude
    ## 1 2011-10-21 23:54:10        -73.99058        40.76107         -73.98113
    ## 2 2015-02-03 10:42:03        -73.98840        40.72343         -73.98965
    ## 3 2014-03-16 18:58:58        -74.01578        40.71511         -74.01203
    ## 4 2009-06-13 16:10:54        -73.97732        40.78728         -73.95803
    ## 5 2014-06-12 03:25:56        -73.98968        40.72972         -73.98249
    ## 6 2011-07-16 01:19:59        -73.99763        40.72181         -74.00976
    ##   dropoff_latitude passenger_count pickup_year pickup_month pickup_day
    ## 1         40.75863               2        2011           10         21
    ## 2         40.74170               1        2015            2          3
    ## 3         40.70789               2        2014            3         16
    ## 4         40.77884               3        2009            6         13
    ## 5         40.76189               3        2014            6         12
    ## 6         40.70994               1        2011            7         16
    ##   pickup_hour pickup_minute pickup_second pickup_weekday pickup_week
    ## 1          23            54            10              6          42
    ## 2          10            42             3              3           5
    ## 3          18            58            58              1          11
    ## 4          16            10            54              7          24
    ## 5           3            25            56              5          24
    ## 6           1            19            59              7          29
    ##   year_cycle  week_cycle
    ## 1  0.7771460 -0.03739119
    ## 2  0.4539905  0.07473009
    ## 3 -0.2756374  1.00000000
    ## 4 -0.9743701  0.56332006
    ## 5 -0.9781476 -0.99371221
    ## 6 -0.6946584  0.03739119

``` r
df_temp <- df %>% select(-"pickup_datetime")

# 最小最大化
normal <- preProcess(df_temp, method = "range", rangeBounds = c(0,1))
train_X <- predict(normal, df_temp)
```

線性迴歸

``` r
train <- data.frame(train_X, fare_amount = train_Y)

control <- trainControl(method="cv", number=5, repeats = 5)
model.lr <- train(fare_amount~., data = train, method = 'glm', trControl=control)
model.lr
```

    ## Generalized Linear Model 
    ## 
    ## 5000 samples
    ##   15 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 4000, 4000, 4000, 3999, 4001 
    ## Resampling results:
    ## 
    ##   RMSE      Rsquared    MAE     
    ##   9.626383  0.02622975  6.005779

梯度提升樹

``` r
control <- trainControl(method="cv", number=5, repeats = 5)
model.gbm <- train(fare_amount~., data = train, method = "gbm", trControl = control, verbose = FALSE)
model.gbm
```

    ## Stochastic Gradient Boosting 
    ## 
    ## 5000 samples
    ##   15 predictor
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 4001, 4000, 3999, 4000, 4000 
    ## Resampling results across tuning parameters:
    ## 
    ##   interaction.depth  n.trees  RMSE      Rsquared   MAE     
    ##   1                   50      7.989173  0.3759271  5.101289
    ##   1                  100      7.464844  0.4338427  4.757734
    ##   1                  150      7.273784  0.4507747  4.602753
    ##   2                   50      6.405453  0.5991507  4.233747
    ##   2                  100      5.887541  0.6425643  3.822349
    ##   2                  150      5.681423  0.6632016  3.651403
    ##   3                   50      5.844755  0.6547681  3.812122
    ##   3                  100      5.472598  0.6853649  3.492078
    ##   3                  150      5.335968  0.6994833  3.332620
    ## 
    ## Tuning parameter 'shrinkage' was held constant at a value of 0.1
    ## 
    ## Tuning parameter 'n.minobsinnode' was held constant at a value of 10
    ## RMSE was used to select the optimal model using the smallest value.
    ## The final values used for the model were n.trees = 150,
    ##  interaction.depth = 3, shrinkage = 0.1 and n.minobsinnode = 10.
