Day028
================

Feature Selection
-----------------

(Kaggle)鐵達尼生存預測精簡版
<https://www.kaggle.com/c/titanic>

Packages loading

``` r
library(heatmaply)
library(glmnet)
library(tidyverse)
library(caret)
library(pROC)
```

Data loading

``` r
df_train <- read.csv("data/titanic_train.csv")
sapply(list(df_train=df_train), dim) %>% 'rownames<-'(c('nrow','ncol')) 
```

    ##      df_train
    ## nrow      891
    ## ncol       12

Setting training and testing data

``` r
train_y <- df_train$Survived
df <- df_train %>% select(-c("Survived","PassengerId"))
df %>% head
```

    ##   Pclass                                                Name    Sex Age
    ## 1      3                             Braund, Mr. Owen Harris   male  22
    ## 2      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38
    ## 3      3                              Heikkinen, Miss. Laina female  26
    ## 4      1        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35
    ## 5      3                            Allen, Mr. William Henry   male  35
    ## 6      3                                    Moran, Mr. James   male  NA
    ##   SibSp Parch           Ticket    Fare Cabin Embarked
    ## 1     1     0        A/5 21171  7.2500              S
    ## 2     1     0         PC 17599 71.2833   C85        C
    ## 3     0     0 STON/O2. 3101282  7.9250              S
    ## 4     1     0           113803 53.1000  C123        S
    ## 5     0     0           373450  8.0500              S
    ## 6     0     0           330877  8.4583              Q

確定只有 integer, numeric, factor 三種類型後, 分別將欄位名稱存於三個 vector 中

``` r
feature_type <- sapply(df, class)
int_var <- feature_type[which(feature_type == "integer")] %>% as.data.frame %>% rownames
num_var <- feature_type[which(feature_type == "numeric")] %>% as.data.frame %>% rownames
fac_var <- feature_type[which(feature_type == "factor")] %>% as.data.frame %>% rownames
list(integer_feature = int_var,
     numeric_feature = num_var,
     factor_feature = fac_var)
```

    ## $integer_feature
    ## [1] "Pclass" "SibSp"  "Parch" 
    ## 
    ## $numeric_feature
    ## [1] "Age"  "Fare"
    ## 
    ## $factor_feature
    ## [1] "Name"     "Sex"      "Ticket"   "Cabin"    "Embarked"

只留數值型欄位

``` r
df <- df %>% select(-fac_var)

# 空值補 -1
df <- df %>% replace(., is.na(.), -1)
df %>% head
```

    ##   Pclass Age SibSp Parch    Fare
    ## 1      3  22     1     0  7.2500
    ## 2      1  38     1     0 71.2833
    ## 3      3  26     0     0  7.9250
    ## 4      1  35     1     0 53.1000
    ## 5      3  35     0     0  8.0500
    ## 6      3  -1     0     0  8.4583

計算df整體相關係數, 並繪製成熱圖

``` r
mat <- df %>% 
  mutate(Survived = train_y) %>%
  cor() %>%
  as.matrix()
heatmaply(mat, draw_cellnote = TRUE, dendrogram="none")
```

![](Day028_files/figure-markdown_github/unnamed-chunk-7-1.png)

作業1
-----

鐵達尼生存率預測中，試著變更兩種以上的相關係數門檻值，觀察預測能力是否提升?

原始特徵 + 邏輯斯迴歸

``` r
# 最小最大化
normal <- preProcess(df, method = "range", rangeBounds = c(0,1))
train_X <- predict(normal, df)

train <- train_X %>% mutate(Survived = as.factor(train_y))
levels(train$Survived) <- make.names(levels(factor(train$Survived)))
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit <- train(Survived~., data=train, method="glm", metric="ROC", trControl=control)
# display results
print(fit)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   5 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 712, 713, 713, 713, 713 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7187444  0.8434195  0.4589514

``` r
glm.probs <- predict(fit, data = train$Survived, type = "prob")
glm.ROC <- roc(response = train$Survived,
               predictor = glm.probs$X1,
               levels = levels(train$Survived))
plot(glm.ROC, type="S", col="red"); text(x=0, y=.25, labels=paste("AUC =", round(glm.ROC$auc, 4)))
```

![](Day028_files/figure-markdown_github/unnamed-chunk-8-1.png)

篩選相關係數1 (正負0.1)

``` r
df_y <- df %>% 
  mutate(Survived = train_y)

cor_index1 <- df_y %>%
  cor(.$Survived) %>%
  {.>.1 | .<(-.1)} %>%
  which

cor_var1 <- colnames(df_y)[cor_index1]
(cor_var1 <- cor_var1[-length(cor_var1)]) # 扣除Survived項
```

    ## [1] "Pclass" "Fare"

特徵1 + 邏輯斯迴歸

``` r
# 最小最大化
normal_cor1 <- preProcess(df[cor_var1], method = "range", rangeBounds = c(0,1))
train_X_cor1 <- predict(normal_cor1, df[cor_var1])

train_cor1 <- train_X_cor1 %>% mutate(Survived = as.factor(train_y))
levels(train_cor1$Survived) <- make.names(levels(factor(train_cor1$Survived)))
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit_cor1 <- train(Survived~., data=train_cor1, method="glm", metric="ROC", trControl=control)
# display results
print(fit_cor1)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   2 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 713, 714, 713, 712, 712 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7056818  0.8542619  0.3974425

``` r
glm.probs <- predict(fit_cor1, data = train_cor1$Survived, type = "prob")
glm.ROC <- roc(response = train_cor1$Survived,
               predictor = glm.probs$X1,
               levels = levels(train_cor1$Survived))
plot(glm.ROC, type="S", col="red"); text(x=0, y=.25, labels=paste("AUC =", round(glm.ROC$auc, 4)))
```

![](Day028_files/figure-markdown_github/unnamed-chunk-10-1.png)

``` r
# 結果 : 準確度下降
```

篩選相關係數1 (正負0.05)

``` r
df_y <- df %>% 
  mutate(Survived = train_y)

cor_index2 <- df_y %>%
  cor(.$Survived) %>%
  {.>.05 | .<(-.05)} %>%
  which

cor_var2 <- colnames(df_y)[cor_index2]
(cor_var2 <- cor_var2[-length(cor_var2)]) # 扣除Survived項
```

    ## [1] "Pclass" "Parch"  "Fare"

特徵2 + 邏輯斯迴歸

``` r
# 最小最大化
normal_cor2 <- preProcess(df[cor_var2], method = "range", rangeBounds = c(0,1))
train_X_cor2 <- predict(normal_cor2, df[cor_var2])

train_cor2 <- train_X_cor2 %>% mutate(Survived = as.factor(train_y))
levels(train_cor2$Survived) <- make.names(levels(factor(train_cor2$Survived)))
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit_cor2 <- train(Survived~., data=train_cor2, method="glm", metric="ROC", trControl=control)
# display results
print(fit_cor2)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   3 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 713, 714, 712, 713, 712 
    ## Resampling results:
    ## 
    ##   ROC        Sens       Spec     
    ##   0.7061557  0.8452377  0.4269395

``` r
glm.probs <- predict(fit_cor2, data = train_cor2$Survived, type = "prob")
glm.ROC <- roc(response = train_cor2$Survived,
               predictor = glm.probs$X1,
               levels = levels(train_cor2$Survived))
plot(glm.ROC, type="S", col="red"); text(x=0, y=.25, labels=paste("AUC =", round(glm.ROC$auc, 4)))
```

![](Day028_files/figure-markdown_github/unnamed-chunk-12-1.png)

``` r
# 結果 : 準確度比特徵一上升，但跟原始比較還是下降
```

作業2
-----

續上題，使用 L1 Embedding 做特徵選擇(自訂門檻)，觀察預測能力是否提升?

``` r
# 最小最大化
normal <- preProcess(df, method = "range", rangeBounds = c(0,1))
train_X <- predict(normal, df)

fit <- cv.glmnet(as.matrix(train_X),as.matrix(train_y) , family="gaussian", alpha=1)
lasso_coeffs <- coef(fit, s=fit$lambda.1se)
lasso_var <- rownames(lasso_coeffs)[which(lasso_coeffs!=0)]
(lasso_var <- lasso_var[-1]) # 扣除(Intercept)項
```

    ## [1] "Pclass" "Fare"

L1\_Embedding 特徵 + 線性迴歸

``` r
# 最小最大化
normal_lasso <- preProcess(df[lasso_var], method = "range", rangeBounds = c(0,1))
train_X_lasso <- predict(normal_lasso, df[lasso_var])

train_lasso <- train_X_lasso %>% mutate(Survived = as.factor(train_y))
levels(train_lasso$Survived) <- make.names(levels(factor(train_lasso$Survived)))
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
fit_lasso <- train(Survived~., data=train_lasso, method="glm", metric="ROC", trControl=control)
# display results
print(fit_lasso)
```

    ## Generalized Linear Model 
    ## 
    ## 891 samples
    ##   2 predictor
    ##   2 classes: 'X0', 'X1' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (5 fold) 
    ## Summary of sample sizes: 713, 714, 712, 713, 712 
    ## Resampling results:
    ## 
    ##   ROC        Sens      Spec     
    ##   0.7070558  0.854362  0.3976982

``` r
glm.probs <- predict(fit_lasso, data = train_lasso$Survived, type = "prob")
glm.ROC <- roc(response = train_lasso$Survived,
               predictor = glm.probs$X1,
               levels = levels(train_lasso$Survived))
plot(glm.ROC, type="S", col="red"); text(x=0, y=.25, labels=paste("AUC =", round(glm.ROC$auc, 4)))
```

![](Day028_files/figure-markdown_github/unnamed-chunk-14-1.png)
