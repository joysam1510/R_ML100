Day044
================

<https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/>

Packages loading

``` r
library(tidyverse)
library(caret)
library(randomForest)
```

讀取鳶尾花資料集

``` r
str(iris)
```

    ## 'data.frame':    150 obs. of  5 variables:
    ##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
    ##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
    ##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
    ##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
    ##  $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...

切分訓練集/測試集

``` r
intrain <- createDataPartition(iris$Species, p=.8, list=FALSE)
train <- iris[intrain,]; test <- iris[-intrain,]
```

Default random forest

``` r
# mtry: Number of variables randomly sampled as candidates at each split.
# ntree: Number of trees to grow.
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry)
# fit the model
control <- trainControl(method="repeatedcv", number=10, repeats=3)
rf_model = train(Species ~ ., data=train, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl = control)
rf_model
```

    ## Random Forest 
    ## 
    ## 120 samples
    ##   4 predictor
    ##   3 classes: 'setosa', 'versicolor', 'virginica' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (10 fold, repeated 3 times) 
    ## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
    ## Resampling results:
    ## 
    ##   Accuracy   Kappa 
    ##   0.9583333  0.9375
    ## 
    ## Tuning parameter 'mtry' was held constant at a value of 2.236068

1.  Tune Using Caret

Only those algorithm parameters that have a large effect (e.g. really require tuning in Khun’s opinion) are available for tuning in caret. As such, only mtry parameter is available in caret for tuning. The reason is its effect on the final accuracy and that it must be found empirically for a dataset.

The ntree parameter is different in that it can be as large as you like, and continues to increases the accuracy up to some point. It is less difficult or critical to tune and could be limited more by compute time available more than anything.

Random Search

``` r
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="random")
#Random generate 3 mtry values with tuneLength = 3
rf_random <- train(Species~., data=train, method="rf", metric="Accuracy", tuneLength=3, trControl=control)
print(rf_random)
```

    ## Random Forest 
    ## 
    ## 120 samples
    ##   4 predictor
    ##   3 classes: 'setosa', 'versicolor', 'virginica' 
    ## 
    ## No pre-processing
    ## Resampling: Cross-Validated (10 fold, repeated 3 times) 
    ## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
    ## Resampling results across tuning parameters:
    ## 
    ##   mtry  Accuracy   Kappa    
    ##   2     0.9638889  0.9458333
    ##   4     0.9666667  0.9500000
    ## 
    ## Accuracy was used to select the optimal model using the largest value.
    ## The final value used for the model was mtry = 4.

``` r
plot(rf_random)
```

![](Day044_files/figure-markdown_github/unnamed-chunk-6-1.png)

``` r
varImp(rf_model)
```

    ## rf variable importance
    ## 
    ##              Overall
    ## Petal.Length  100.00
    ## Petal.Width    90.76
    ## Sepal.Length   16.68
    ## Sepal.Width     0.00

``` r
rf.pred = predict(rf_model, newdata = test)
table(rf.pred, test$Species)
```

    ##             
    ## rf.pred      setosa versicolor virginica
    ##   setosa         10          0         0
    ##   versicolor      0          9         0
    ##   virginica       0          1        10

``` r
(error.rate = round(mean(rf.pred != test$Species),2))
```

    ## [1] 0.03

1.  Tune Using Algorithm Tools

Some algorithms provide tools for tuning the parameters of the algorithm.

For example, the random forest algorithm implementation in the randomForest package provides the tuneRF() function that searches for optimal mtry values given your data.

``` r
# Algorithm Tune (tuneRF)
bestmtry <- tuneRF(x=train[,1:4], y=train$Species, stepFactor=1.5, improve=1e-5, ntree=500)
```

    ## mtry = 2  OOB error = 3.33% 
    ## Searching left ...
    ## Searching right ...
    ## mtry = 3     OOB error = 3.33% 
    ## 0 1e-05

![](Day044_files/figure-markdown_github/unnamed-chunk-10-1.png)

``` r
print(bestmtry)
```

    ##       mtry   OOBError
    ## 2.OOB    2 0.03333333
    ## 3.OOB    3 0.03333333

This does not really match up with what we saw in the caret repeated cross validation experiment above, where mtry=10 gave an accuracy of 82.04%. Nevertheless, it is an alternate way to tune the algorithm.
